{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "P(H|E) = (P(E|H) * P(H)) / P(E)\n",
    "\n",
    "где\n",
    "\n",
    "P(H|E) – вероятность гипотезы H наступления данного события E, при условии, что событие E наступило(апостериорная вероятность).\n",
    "P(E|H) – вероятность события E при условии, что гипотеза H истинна.\n",
    "P(H) – это вероятность того, что гипотеза H истинна (независимо от любого связанного с ней события), или априорная вероятность H.\n",
    "P(E) – вероятность наступления события (независимо от гипотезы)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Пример.\n",
    "Допустим, нам интересно узнать, является ли письмо, содержащее слово sex (событие), спамом (гипотезой). Если вернуться к описанию теоремы, то эту задачу можно сформулировать так::\n",
    "\n",
    "P(class=SPAM|contains=\"sex\") = (P(contains=\"sex\"|class=SPAM) * P(class=SPAM)) / P(contains=\"sex\")\n",
    "\n",
    "Вероятность того, что электронное письмо, содержащее слово sex, является спамом, равна доле СПАМ-писем, содержащих слово sex , умноженной на долю электронных писем, являющихся спамом, и деленной на долю электронных писем, содержащих слово sex."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Давайте разберем это по кусочкам:\n",
    "\n",
    "    P(class=SPAM|contains=\"sex\") – вероятность того, что письмо будет СПАМОМ, учитывая, что это письмо содержит слово sex. Именно это мы и хотим предсказать.\n",
    "    \n",
    "    P(contains=\"sex\"|class=SPAM) – вероятность того, что письмо, которое было распознано как СПАМ, содержит слово sex. Это наши обучающие данные, которые представляют корреляцию между электронной почтой, считающейся СПАМОМ, и такой электронной почтой, содержащей слово sex .\n",
    "    \n",
    "    P(class=SPAM) – это вероятность того, что письмо будет СПАМОМ (без какого-либо предварительного знания слов, которые оно содержит). Это просто доля электронных писем, являющихся спамом во всем нашем учебном наборе. Мы умножаем на это значение, потому что нам интересно знать, насколько важна информация о СПАМЕ. Если это значение низкое, то значимость любых событий, связанных со спамом, также будет низкой.\n",
    "    \n",
    "    P(contains=\"sex\") - вероятность того, что электронное письмо содержит слово sex . Это просто доля электронных писем, содержащих слово секс во всем нашем обучающем наборе. Мы делим на это значение, потому что чем более исключительным является слово sex , тем важнее контекст, в котором оно появляется. Таким образом, если это число невелико (слово появляется очень редко), оно может быть отличным индикатором того, что в тех случаях, когда оно действительно появляется, оно является релевантной характеристикой для анализа."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Таким образом, теорема Байеса позволяет нам делать обоснованные выводы о событиях, происходящих в реальном мире, основываясь на предварительном знании наблюдений, которые могут подразумевать это. Чтобы применить эту теорему к любой задаче, нам нужно вычислить два типа вероятностей, которые появляются в формуле."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятности классов"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "В теореме P(A) представляет вероятности каждого события. В Наивном Байесовском классификаторе мы можем интерпретировать эти вероятности классов как просто частоту каждого экземпляра события, деленную на общее число экземпляров. Например, в предыдущем примере обнаружения спама P(class=SPAM) представляет собой количество писем, классифицированных как спам, деленное на сумму всех экземпляров (это spam + not spam ):\n",
    "\n",
    "P(class=SPAM) = count(class=SPAM) / (count(class=notSPAM) + count(class=SPAM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Условные вероятности"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "В теореме P(A|B) представляет условные вероятности события A при наступлении другого события B. В Наивном байесовском классификаторе они кодируют апостериорную вероятность того, что A произойдет, когда B истинно.\n",
    "\n",
    "Для примера спама P(class=SPAM|contains=\"sex\") представляет количество экземпляров, в которых электронное письмо считается спамом и содержит слово sex , деленное на общее количество электронных писем, содержащих слово sex :\n",
    "\n",
    "P(class=SPAM|contains=\"sex\") = count(class=SPAM & contains=sex) / count(contains=sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приложения"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Применение наивного Байесовского классификатора было показано успешным в различных сценариях. Классическим вариантом использования является классификация документов: определение того, соответствует ли данный документ определенным категориям. Тем не менее, эта техника имеет свои преимущества и ограничения.\n",
    "\n",
    "Для загрузки данных мы можем использовать метод Pandas Data frame read_table. Это позволяет нам определить разделитель (в данном случае табуляцию) и соответствующим образом переименовать столбцы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_table('SMSSpamCollection',\n",
    "                   sep='\\t', \n",
    "                   header=None,\n",
    "                   names=['label', 'message'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предварительная обработка"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Как только наши данные будут готовы, пришло время сделать некоторую предварительную обработку. Мы сосредоточимся на устранении бесполезных отклонений для нашей задачи. \n",
    "\n",
    "Во-первых, мы должны преобразовать метки из строк в двоичные значения для нашего классификатора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "5567    1\n",
       "5568    0\n",
       "5569    0\n",
       "5570    0\n",
       "5571    0\n",
       "Name: label, Length: 5572, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.label.map({'ham': 0, 'spam': 1})\n",
    "df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       go until jurong point, crazy.. available only ...\n",
       "1                           ok lar... joking wif u oni...\n",
       "2       free entry in 2 a wkly comp to win fa cup fina...\n",
       "3       u dun say so early hor... u c already then say...\n",
       "4       nah i don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    this is the 2nd time we have tried 2 contact u...\n",
       "5568                 will ü b going to esplanade fr home?\n",
       "5569    pity, * was in mood for that. so...any other s...\n",
       "5570    the guy did some bitching but i acted like i'd...\n",
       "5571                           rofl. its true to its name\n",
       "Name: message, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Во-вторых, преобразуйте все символы в сообщении в нижний регистр:\n",
    "df['message'] = df.message.map(lambda x: x.lower())\n",
    "df['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       go until jurong point crazy available only in ...\n",
       "1                                 ok lar joking wif u oni\n",
       "2       free entry in 2 a wkly comp to win fa cup fina...\n",
       "3             u dun say so early hor u c already then say\n",
       "4       nah i dont think he goes to usf he lives aroun...\n",
       "                              ...                        \n",
       "5567    this is the 2nd time we have tried 2 contact u...\n",
       "5568                  will ü b going to esplanade fr home\n",
       "5569    pity  was in mood for that soany other suggest...\n",
       "5570    the guy did some bitching but i acted like id ...\n",
       "5571                            rofl its true to its name\n",
       "Name: message, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# В-третьих, удалите все знаки препинания:\n",
    "df['message'] = df.message.str.replace('[^\\w\\s]', '')\n",
    "df['message']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "В-четвертых, токенизируйте сообщения в отдельные слова с помощью nltk . Во-первых, мы должны импортировать и загрузить токенизатор из консоли:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u dun say so early hor u c already then say'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['message'] = df.message.str.replace('[^\\w\\s]', '')\n",
    "df['message'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message'] = df['message'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "В-пятых, мы выполним определение корней слов. Идея выделения корней состоит в том, чтобы нормализовать наш текст, так как все варианты слов несут одно и то же значение, независимо от времени. Один из самых популярных алгоритмов стемминга - Porter Stemmer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    " \n",
    "df['message'] = df['message'].apply(lambda x: [stemmer.stem(y) for y in x])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Наконец, мы преобразуем входные данные, которые будут функциями, которые мы будем вводить в нашу модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Конвертируем список слов в строку слов разделенных пробелами\n",
    "df['message'] = df['message'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "counts = count_vect.fit_transform(df['message'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x8169 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 72500 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Мы могли бы оставить его как простой подсчет слов на сообщение, но лучше использовать Term Frequency Inverse Document Frequency, более известный как tf-idf :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer().fit(counts)\n",
    "\n",
    "counts = transformer.transform(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       go until jurong point crazi avail onli in bugi...\n",
       "1                                   ok lar joke wif u oni\n",
       "2       free entri in 2 a wkli comp to win fa cup fina...\n",
       "3             u dun say so earli hor u c alreadi then say\n",
       "4       nah i dont think he goe to usf he live around ...\n",
       "                              ...                        \n",
       "5567    thi is the 2nd time we have tri 2 contact u u ...\n",
       "5568                      will ü b go to esplanad fr home\n",
       "5569         piti wa in mood for that soani other suggest\n",
       "5570    the guy did some bitch but i act like id be in...\n",
       "5571                              rofl it true to it name\n",
       "Name: message, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда мы выполнили извлечение признаков из наших данных, пришло время построить нашу модель. Мы начнем с разделения ваших данных на обучающие и тестовые наборы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.1, random_state=69)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Затем все, что нам нужно сделать, это инициализировать Наивный байесовский классификатор и подогнать данные. Для задач классификации текстов хорошо подходит Полиномиальный наивный байесовский классификатор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка модели"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "После того, как мы собрали наш классификатор, мы можем оценить его производительность в тестовом наборе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "верность = 94.8%\n",
      "доля спама = 0.0%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "accuracy = np.mean(predicted == y_test)\n",
    "\n",
    "# numb_spam = np.mean(df['message'] == 1)\n",
    "\n",
    "print('верность = {0:.1%}'.format(accuracy))\n",
    "#print('доля спама = {0:.1%}'.format(numb_spam))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Поздравляю! Наш простой наивный байесовский классификатор имеет точность 94,8% с этим конкретным тестовым набором! Но этого недостаточно, просто обеспечивая точность, поскольку наш набор данных несбалансирован, когда дело доходит до меток (86,6% легитимных в отличие от 13,4% спама). Может случиться так, что наш классификатор переоснащает законный класс, игнорируя класс спама. Чтобы решить эту неопределенность, давайте взглянем на матрицу путаницы :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[482   0]\n",
      " [ 29  47]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, predicted))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Как мы видим, количество ошибок довольно сбалансировано между законным и спамом, причем 0 законных сообщения классифицируются как спам и 29 спам-сообщений классифицируются как законные. В целом, это очень хорошие результаты для нашего простого классификатора."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Источник: https://pythobyte.com/the-naive-bayes-algorithm-in-python-with-scikit-learn-0473e7f9/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
